---
title: Langflow TypeScript 客户端
slug: /typescript-client
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Langflow TypeScript 客户端允许您的 TypeScript 应用程序通过编程方式与 Langflow API 进行交互。

有关客户端代码仓库，请参阅 [langflow-client-ts](https://github.com/datastax/langflow-client-ts/)。

有关 npm 包，请参阅 [@datastax/langflow-client](https://www.npmjs.com/package/@datastax/langflow-client)。

## 安装 Langflow TypeScript 包

要安装 Langflow TypeScript 客户端包，请使用以下命令之一：

<Tabs>
<TabItem value="npm" label="npm" default>

```bash
npm install @datastax/langflow-client
```

</TabItem>
<TabItem value="yarn" label="yarn">

```bash
yarn add @datastax/langflow-client
```

</TabItem>
<TabItem value="pnpm" label="pnpm">

```bash
pnpm add @datastax/langflow-client
```

</TabItem>
</Tabs>

## 初始化 Langflow TypeScript 客户端

1. 将客户端导入到您的代码中。

    ```tsx
    import { LangflowClient } from "@datastax/langflow-client";
    ```

2. 初始化一个 `LangflowClient` 对象来与您的服务器交互：

    ```tsx
    const baseUrl = "BASE_URL";
    const apiKey = "API_KEY";
    const client = new LangflowClient({ baseUrl, apiKey });
    ```

    将 `BASE_URL` 和 `API_KEY` 替换为您部署的值。
    默认的 Langflow 基础 URL 是 `http://localhost:7860`。
    要创建 API 密钥，请参阅 [API 密钥](/configuration-api-keys)。

## Langflow TypeScript 客户端快速入门

1. 在初始化 Langflow 客户端后，通过调用您的 Langflow 服务器来测试连接。

    以下示例通过发送流程 ID 和聊天输入字符串来运行流程（`runFlow`）：

    ```tsx
    import { LangflowClient } from "@datastax/langflow-client";

    const baseUrl = "http://localhost:7860";
    const client = new LangflowClient({ baseUrl });

    async function runFlow() {
        const flowId = "aa5a238b-02c0-4f03-bc5c-cc3a83335cdf";
        const flow = client.flow(flowId);
        const input = "Is anyone there?";

        const response = await flow.run(input);
        console.log(response);
    }

    runFlow().catch(console.error);
    ```

    替换以下内容：

    * `baseUrl`：您的 Langflow 服务器的 URL
    * `flowId`：您要运行的流程的 ID
    * `input`：您要发送以触发流程的聊天输入消息


2. 检查结果以确认客户端已连接到您的 Langflow 服务器。

    以下示例显示了成功到达 Langflow 服务器并成功启动流程的格式良好的 `runFlow` 请求的响应：

    ```
    FlowResponse {
      sessionId: 'aa5a238b-02c0-4f03-bc5c-cc3a83335cdf',
      outputs: [ { inputs: [Object], outputs: [Array] } ]
    }
    ```

    在这种情况下，响应包括一个 [`sessionID`](/session-id)，它是客户端-服务器会话的唯一标识符，以及一个包含有关流程运行信息的 `outputs` 数组。

3. 如果您想从服务器获取完整的响应对象，请将 `console.log` 更改为字符串化返回的 JSON 对象：

    ```tsx
    console.log(JSON.stringify(response, null, 2));
    ```

    返回的 `inputs` 和 `outputs` 对象的确切结构取决于您的流程的组件和配置。

4. 如果您希望响应仅包含来自**聊天输出**组件的聊天消息，请将 `console.log` 更改为使用 `chatOutputText` 便利函数：

    ```tsx
    console.log(response.chatOutputText());
    ```

## 使用高级 TypeScript 客户端功能

TypeScript 客户端不仅可以连接到您的服务器并运行流程。

此示例在快速入门的基础上添加了与 Langflow 交互的其他功能。

1. 将调整作为对象与请求一起传递给您的代码。

    调整会为对您的流程的所有调用更改组件内的值。

    此示例调整 OpenAI 模型组件以强制使用 `gpt-4o-mini` 模型：

    ```tsx
    const tweaks = { model_name: "gpt-4o-mini" };
    ```

2. 在请求中传递一个[会话 ID](/session-id) 以将对话与其他流程运行分开，并能够在将来通过调用相同的会话 ID 来继续此对话：

    ```tsx
    const session_id = "aa5a238b-02c0-4f03-bc5c-cc3a83335cdf";
    ```

3. 不要在 Flow 对象上调用 `run`，而是使用相同的参数调用 `stream`：

    ```tsx
    const response = await client.flow(flowId).stream(input);

    for await (const event of response) {
      console.log(event);
    }
    ```

    响应是一个对象的 [`ReadableStream`](https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream)。
    有关流式 Langflow 响应的更多信息，请参阅 [`/run` 端点](/api-flows-run#run-flow)。

4. 运行修改后的 TypeScript 应用程序以使用 `tweaks` 和 `session_id` 运行流程，然后流式返回响应。

将 `baseUrl` 和 `flowId` 替换为您部署的值。

    ```tsx
    import { LangflowClient } from "@datastax/langflow-client";

    const baseUrl = "http://localhost:7860";
    const client = new LangflowClient({ baseUrl });

    async function runFlow() {
        const flowId = "aa5a238b-02c0-4f03-bc5c-cc3a83335cdf";
        const input = "Is anyone there?";
        const tweaks = { model_name: "gpt-4o-mini" };
        const session_id = "test-session";

        const response = await client.flow(flowId).stream(input, {
            session_id,
            tweaks,
          });

        for await (const event of response) {
            console.log(event);
        }

    }
    runFlow().catch(console.error);
    ```

    将 `baseUrl` 和 `flowId` 替换为您的服务器 URL 和流程 ID，就像您在上一次运行中所做的那样。

    <details>
    <summary>结果</summary>

    启用流式传输后，响应包括流程元数据和流程活动的时间戳事件。
    例如：

    ```text
    {
      event: 'add_message',
      data: {
        timestamp: '2025-05-23 15:52:48 UTC',
        sender: 'User',
        sender_name: 'User',
        session_id: 'test-session',
        text: 'Is anyone there?',
        files: [],
        error: false,
        edit: false,
        properties: {
          text_color: '',
          background_color: '',
          edited: false,
          source: [Object],
          icon: '',
          allow_markdown: false,
          positive_feedback: null,
          state: 'complete',
          targets: []
        },
        category: 'message',
        content_blocks: [],
        id: '7f096715-3f2d-4d84-88d6-5e2f76bf3fbe',
        flow_id: 'aa5a238b-02c0-4f03-bc5c-cc3a83335cdf',
        duration: null
      }
    }
    {
      event: 'token',
      data: {
        chunk: 'Absolutely',
        id: 'c5a99314-6b23-488b-84e2-038aa3e87fb5',
        timestamp: '2025-05-23 15:52:48 UTC'
      }
    }
    {
      event: 'token',
      data: {
        chunk: ',',
        id: 'c5a99314-6b23-488b-84e2-038aa3e87fb5',
        timestamp: '2025-05-23 15:52:48 UTC'
      }
    }
    {
      event: 'token',
      data: {
        chunk: " I'm",
        id: 'c5a99314-6b23-488b-84e2-038aa3e87fb5',
        timestamp: '2025-05-23 15:52:48 UTC'
      }
    }
    {
      event: 'token',
      data: {
        chunk: ' here',
        id: 'c5a99314-6b23-488b-84e2-038aa3e87fb5',
        timestamp: '2025-05-23 15:52:48 UTC'
      }
    }

    // this response is abbreviated

    {
      event: 'end',
      data: { result: { session_id: 'test-session', outputs: [Array] } }
    }
    ```

    </details>

## Retrieve Langflow logs with the TypeScript client

To retrieve [Langflow logs](/logging), you must enable log retrieval on your Langflow server by including the following values in your server's `.env` file:

```text
LANGFLOW_ENABLE_LOG_RETRIEVAL=true
LANGFLOW_LOG_RETRIEVER_BUFFER_SIZE=10000
LANGFLOW_LOG_LEVEL=DEBUG
```

The following example script starts streaming logs in the background, and then runs a flow so you can monitor the flow run:

```tsx
import { LangflowClient } from "@datastax/langflow-client";

const baseUrl = "http://localhost:7863";
const flowId = "86f0bf45-0544-4e88-b0b1-8e622da7a7f0";

async function runFlow(client: LangflowClient) {
    const input = "Is anyone there?";
    const response = await client.flow(flowId).run(input);
    console.log('Flow response:', response);
}

async function main() {
    const client = new LangflowClient({ baseUrl: baseUrl });

    // Start streaming logs
    console.log('Starting log stream...');
    for await (const log of await client.logs.stream()) {
        console.log('Log:', log);
    }

    // Run the flow
    await runFlow(client);

}

main().catch(console.error);
```

Replace `baseUrl` and `flowId` with your server URL and flow ID, as you did in the previous run.

Logs begin streaming indefinitely, and the flow runs once.

The following example result is truncated for readability, but you can follow the messages to see how the flow instantiates its components, configures its model, and processes the outputs.

The `FlowResponse` object, at the end of the stream, is returned to the client with the flow result in the `outputs` array.

<details>
<summary>Result</summary>

```text
Starting log stream...
Log: Log {
  timestamp: 2025-05-30T11:49:16.006Z,
  message: '2025-05-30T07:49:16.006127-0400 DEBUG Instantiating ChatInput of type component\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.029Z,
  message: '2025-05-30T07:49:16.029957-0400 DEBUG Instantiating Prompt of type component\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.049Z,
  message: '2025-05-30T07:49:16.049520-0400 DEBUG Instantiating ChatOutput of type component\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.069Z,
  message: '2025-05-30T07:49:16.069359-0400 DEBUG Instantiating OpenAIModel of type component\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.086Z,
  message: "2025-05-30T07:49:16.086426-0400 DEBUG Running layer 0 with 2 tasks, ['ChatInput-xjucM', 'Prompt-I3pxU']\n"
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.101Z,
  message: '2025-05-30T07:49:16.101766-0400 DEBUG Building Chat Input\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.113Z,
  message: '2025-05-30T07:49:16.113343-0400 DEBUG Building Prompt\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.131Z,
  message: '2025-05-30T07:49:16.131423-0400 DEBUG Logged vertex build: 6bd9fe9c-5eea-4f05-a96d-f6de9dc77e3c\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.143Z,
  message: '2025-05-30T07:49:16.143295-0400 DEBUG Logged vertex build: 39c68ec9-3859-4fff-9b14-80b3271f8fbf\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.188Z,
  message: "2025-05-30T07:49:16.188730-0400 DEBUG Running layer 1 with 1 tasks, ['OpenAIModel-RtlZm']\n"
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.201Z,
  message: '2025-05-30T07:49:16.201946-0400 DEBUG Building OpenAI\n'
}
Log: Log {
  timestamp: 2025-05-30T11:49:16.216Z,
  message: '2025-05-30T07:49:16.216622-0400 INFO Model name: gpt-4.1-mini\n'
}
Flow response: FlowResponse {
  sessionId: '86f0bf45-0544-4e88-b0b1-8e622da7a7f0',
  outputs: [ { inputs: [Object], outputs: [Array] } ]
}
Log: Log {
  timestamp: 2025-05-30T11:49:18.094Z,
  message: `2025-05-30T07:49:18.094364-0400 DEBUG Vertex OpenAIModel-RtlZm, result: <langflow.graph.utils.UnbuiltResult object at 0x364d24dd0>, object: {'text_output': "Hey there! I'm here and ready to help you build something awesome with AI. What are you thinking about creating today?"}\n`
}
```

</details>

有关更多信息，请参阅[日志端点](/api-logs)。